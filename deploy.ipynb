{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725bee2-318f-4938-9a95-8e7455af2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gradio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65db1222-0617-40f6-879c-226650acd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the input data to generate cleaned and structured datasets\n",
    "    for Depression, Stress, and Anxiety.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input data containing survey responses.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed Depression dataset.\n",
    "        pd.DataFrame: Preprocessed Stress dataset.\n",
    "        pd.DataFrame: Preprocessed Anxiety dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Clean and transform the data\n",
    "        data_1 = data.copy()\n",
    "        data_1['major'] = data_1['major'].replace(np.nan, 'No Degree')\n",
    "        def assign_age_group(age):\n",
    "            if age <= 10:\n",
    "                return 'Under 10'\n",
    "            elif 10 <= age <= 16:\n",
    "                return 'Primary Children'\n",
    "            elif 17 <= age <= 21:\n",
    "                return 'Secondary Children'\n",
    "            elif 22 <= age <= 35:\n",
    "                return 'Adults'\n",
    "            elif 36 <= age <= 48:\n",
    "                return 'Elder Adults'\n",
    "            elif age >= 49:\n",
    "                return 'Older People'\n",
    "            return 'Unknown'\n",
    "\n",
    "        # Create Age_Groups column if it doesn't exist\n",
    "        if 'Age_Groups' not in data_1.columns:\n",
    "            data_1['Age_Groups'] = data_1['age'].apply(assign_age_group)\n",
    "        # Drop unnecessary columns\n",
    "        # data_1 = data_1.drop(data_1.iloc[:, 43:44], axis=1)\n",
    "        data_1 = data_1.drop(columns=['source'], errors='ignore')\n",
    "        # Further cleaning and transformation\n",
    "        data_2 = data_1.copy()\n",
    "        # data_2 = data_2.drop(data_2.iloc[:, 51:69], axis=1)\n",
    "        columns_to_drop = [f\"VCL{i}\" for i in range(1, 17)]\n",
    "        data_2 = data_2.drop(columns=columns_to_drop, errors='ignore')\n",
    "        data_2 = data_2.replace(to_replace=0, value=3)\n",
    "        data_2 = data_2.rename(columns={\n",
    "            'TIPI1': 'Extraverted-enthusiastic',\n",
    "            'TIPI2': 'Critical-quarrelsome',\n",
    "            'TIPI3': 'Dependable-self_disciplined',\n",
    "            'TIPI4': 'Anxious-easily upset',\n",
    "            'TIPI5': 'Open to new experiences-complex',\n",
    "            'TIPI6': 'Reserved-quiet',\n",
    "            'TIPI7': 'Sympathetic-warm',\n",
    "            'TIPI8': 'Disorganized-careless',\n",
    "            'TIPI9': 'Calm-emotionally_stable',\n",
    "            'TIPI10': 'Conventional-uncreative'\n",
    "        })\n",
    "\n",
    "        # Replace inf/-inf and drop NaN values\n",
    "        data_2 = data_2.replace([np.inf, -np.inf], np.nan)\n",
    "        data_2 = data_2.dropna()\n",
    "\n",
    "        # Step 2: Extract new_data and DASS-related data\n",
    "        new_data = data_2.iloc[:, 42:]\n",
    "        data_3 = data_2.filter(regex=r'Q\\d{1,2}A')\n",
    "        # breakpoint()\n",
    "        # Adjust responses for DASS keys\n",
    "        data_3 = data_3.subtract(1, axis=1)\n",
    "\n",
    "        # Step 3: Create Depression, Stress, and Anxiety datasets\n",
    "        DASS_keys = {\n",
    "            'Depression': [3, 5, 10, 13, 16, 17, 21, 24, 26, 31, 34, 37, 38, 42],\n",
    "            'Anxiety': [2, 4, 7, 9, 15, 19, 20, 23, 25, 28, 30, 36, 40, 41],\n",
    "            'Stress': [1, 6, 8, 11, 12, 14, 18, 22, 27, 29, 32, 33, 35, 39]\n",
    "        }\n",
    "\n",
    "        depression_cols = [f\"Q{i}A\" for i in DASS_keys[\"Depression\"]]\n",
    "        stress_cols = [f\"Q{i}A\" for i in DASS_keys[\"Stress\"]]\n",
    "        anxiety_cols = [f\"Q{i}A\" for i in DASS_keys[\"Anxiety\"]]\n",
    "\n",
    "        depression = data_3.filter(depression_cols)\n",
    "        stress = data_3.filter(stress_cols)\n",
    "        anxiety = data_3.filter(anxiety_cols)\n",
    "\n",
    "        # Calculate scores for each category\n",
    "        for dataset in [depression, stress, anxiety]:\n",
    "            dataset['Total_Count'] = dataset.sum(axis=1)\n",
    "        # breakpoint()\n",
    "        # Merge with new_data for additional information\n",
    "        Depression = pd.merge(depression, new_data, how='left', left_index=True, right_index=True)\n",
    "        Stress = pd.merge(stress, new_data, how='inner', left_index=True, right_index=True)\n",
    "        Anxiety = pd.merge(anxiety, new_data, how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "        # Step 4: Transform Age_Groups\n",
    "        def change_var(x):\n",
    "            if x == 'Primary Children':\n",
    "                return 0\n",
    "            elif x == 'Secondary Children':\n",
    "                return 1\n",
    "            elif x == 'Adults':\n",
    "                return 2\n",
    "            elif x == 'Elder Adults':\n",
    "                return 3\n",
    "            elif x == 'Older People':\n",
    "                return 4\n",
    "            return np.nan  # Default if value is unexpected\n",
    "        \n",
    "        for dataset in [Depression, Stress, Anxiety]:\n",
    "            if 'Age_Groups' in dataset.columns:\n",
    "                dataset['Age_Groups'] = dataset['Age_Groups'].apply(change_var)\n",
    "        # Drop NaN values\n",
    "        \n",
    "        Depression = Depression.dropna()\n",
    "        Stress = Stress.dropna()\n",
    "        Anxiety = Anxiety.dropna()\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        for dataset in [Depression, Stress, Anxiety]:\n",
    "            dataset.drop(columns=['Total_Count', 'country', 'age', 'major'], inplace=True, errors='ignore')\n",
    "        \n",
    "        return Depression, Stress, Anxiety\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing data: {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def encode_demographics(data):\n",
    "    encoding_map = {\n",
    "        \"education\": {\"Less than high school\": 1, \"High school\": 2, \"University degree\": 3, \"Graduate degree\": 4},\n",
    "        \"urban\": {\"Rural\": 1, \"Suburban\": 2, \"Urban\": 3},\n",
    "        \"gender\": {\"Male\": 1, \"Female\": 2, \"Other\": 3},\n",
    "        \"engnat\": {\"Yes\": 1, \"No\": 2},\n",
    "        \"age\": None,  # Numeric input\n",
    "        \"hand\": {\"Right\": 1, \"Left\": 2, \"Both\": 3},\n",
    "        \"religion\": {\n",
    "            \"Agnostic\": 1, \"Atheist\": 2, \"Buddhist\": 3, \"Christian (Catholic)\": 4,\n",
    "            \"Christian (Mormon)\": 5, \"Christian (Protestant)\": 6, \"Christian (Other)\": 7,\n",
    "            \"Hindu\": 8, \"Jewish\": 9, \"Muslim\": 10, \"Sikh\": 11, \"Other\": 12\n",
    "        },\n",
    "        \"orientation\": {\"Heterosexual\": 1, \"Bisexual\": 2, \"Homosexual\": 3, \"Asexual\": 4, \"Other\": 5},\n",
    "        \"race\": {\"Asian\": 10, \"Arab\": 20, \"Black\": 30, \"Indigenous Australian\": 40, \"Native American\": 50, \"White\": 60, \"Other\": 70},\n",
    "        \"voted\": {\"Yes\": 1, \"No\": 2},\n",
    "        \"married\": {\"Never married\": 1, \"Currently married\": 2, \"Previously married\": 3},\n",
    "        \"familysize\": None,  # Numeric input\n",
    "        \"major\": None,       # Text input\n",
    "    }\n",
    "    for col, mapping in encoding_map.items():\n",
    "        if mapping:  # If an encoding map is provided\n",
    "            if col in data.columns:\n",
    "                print(f\"Encoding column: {col}\")\n",
    "                data[col] = data[col].replace(mapping)\n",
    "        else:\n",
    "            print(f\"Skipping encoding for column: {col} (no mapping provided)\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031e924d-8902-45a4-bb82-256836e68efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'survey_results.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the CSV file to store the data\n",
    "output_file = \"survey_results.csv\"\n",
    "\n",
    "# Define the column names for the blank CSV initialization\n",
    "columns_order = [\n",
    "    *[f\"Q{i}A\" for i in range(1, 43)],\n",
    "    \"country\", \"source\",\n",
    "    *[f\"TIPI{i}\" for i in range(1, 11)],\n",
    "    *[f\"VCL{i}\" for i in range(1, 17)],\n",
    "    \"education\", \"urban\", \"gender\", \"engnat\", \"age\", \"screensize\",\n",
    "    \"uniquenetworklocation\", \"hand\", \"religion\", \"orientation\", \"race\",\n",
    "    \"voted\", \"married\", \"familysize\", \"major\"\n",
    "]\n",
    "\n",
    "# Create a blank CSV file if it does not exist\n",
    "if not os.path.exists(output_file):\n",
    "    # Create an empty DataFrame with the required columns\n",
    "    empty_df = pd.DataFrame(columns=columns_order)\n",
    "    empty_df.to_csv(output_file, index=False)\n",
    "    print(f\"Blank CSV file '{output_file}' created.\")\n",
    "else:\n",
    "    print(f\"File '{output_file}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c345891f-cb1d-4464-b38a-ca5362bfa00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from requests import get\n",
    "\n",
    "# Questions\n",
    "dass_questions = [\n",
    "    f\"Q{i}A: {desc}\"\n",
    "    for i, desc in enumerate(\n",
    "        [\n",
    "            \"I found myself getting upset by quite trivial things.\",\n",
    "            \"I was aware of dryness of my mouth.\",\n",
    "            \"I couldn't seem to experience any positive feeling at all.\",\n",
    "            \"I experienced breathing difficulty (e.g., excessively rapid breathing).\",\n",
    "            \"I just couldn't seem to get going.\",\n",
    "            \"I tended to over-react to situations.\",\n",
    "            \"I had a feeling of shakiness.\",\n",
    "            \"I found it difficult to relax.\",\n",
    "            \"I found myself in situations that made me so anxious I was most relieved when they ended.\",\n",
    "            \"I felt that I had nothing to look forward to.\",\n",
    "            \"I found myself getting upset rather easily.\",\n",
    "            \"I felt that I was using a lot of nervous energy.\",\n",
    "            \"I felt sad and depressed.\",\n",
    "            \"I found myself getting impatient when I was delayed.\",\n",
    "            \"I had a feeling of faintness.\",\n",
    "            \"I felt that I had lost interest in just about everything.\",\n",
    "            \"I felt I wasn't worth much as a person.\",\n",
    "            \"I felt that I was rather touchy.\",\n",
    "            \"I perspired noticeably in the absence of high temperatures or physical exertion.\",\n",
    "            \"I felt scared without any good reason.\",\n",
    "            \"I felt that life wasn't worthwhile.\",\n",
    "            \"I found it hard to wind down.\",\n",
    "            \"I had difficulty in swallowing.\",\n",
    "            \"I couldn't seem to get any enjoyment out of the things I did.\",\n",
    "            \"I was aware of the action of my heart in the absence of physical exertion.\",\n",
    "            \"I felt down-hearted and blue.\",\n",
    "            \"I found that I was very irritable.\",\n",
    "            \"I felt I was close to panic.\",\n",
    "            \"I found it hard to calm down after something upset me.\",\n",
    "            \"I feared that I would be 'thrown' by some trivial but unfamiliar task.\",\n",
    "            \"I was unable to become enthusiastic about anything.\",\n",
    "            \"I found it difficult to tolerate interruptions to what I was doing.\",\n",
    "            \"I was in a state of nervous tension.\",\n",
    "            \"I felt I was pretty worthless.\",\n",
    "            \"I was intolerant of anything that kept me from getting on with what I was doing.\",\n",
    "            \"I felt terrified.\",\n",
    "            \"I could see nothing in the future to be hopeful about.\",\n",
    "            \"I felt that life was meaningless.\",\n",
    "            \"I found myself getting agitated.\",\n",
    "            \"I was worried about situations in which I might panic and make a fool of myself.\",\n",
    "            \"I experienced trembling.\",\n",
    "            \"I found it difficult to work up the initiative to do things.\",\n",
    "        ],\n",
    "        start=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Options for responses\n",
    "dass_options = {\n",
    "    \"Did not apply to me at all\": 1,\n",
    "    \"Applied to me to some degree, or some of the time\": 2,\n",
    "    \"Applied to me to a considerable degree, or a good part of the time\": 3,\n",
    "    \"Applied to me very much, or most of the time\": 4,\n",
    "}\n",
    "\n",
    "# TIPI Questions\n",
    "tipi_questions = [\n",
    "    \"Extraverted, enthusiastic.\",\n",
    "    \"Critical, quarrelsome.\",\n",
    "    \"Dependable, self-disciplined.\",\n",
    "    \"Anxious, easily upset.\",\n",
    "    \"Open to new experiences, complex.\",\n",
    "    \"Reserved, quiet.\",\n",
    "    \"Sympathetic, warm.\",\n",
    "    \"Disorganized, careless.\",\n",
    "    \"Calm, emotionally stable.\",\n",
    "    \"Conventional, uncreative.\",\n",
    "]\n",
    "\n",
    "# TIPI Options\n",
    "tipi_options = {\n",
    "    \"Disagree strongly\": 1,\n",
    "    \"Disagree moderately\": 2,\n",
    "    \"Disagree a little\": 3,\n",
    "    \"Neither agree nor disagree\": 4,\n",
    "    \"Agree a little\": 5,\n",
    "    \"Agree moderately\": 6,\n",
    "    \"Agree strongly\": 7,\n",
    "}\n",
    "\n",
    "# VCL Words\n",
    "vcl_words = [\n",
    "    \"boat\", \"incoherent\", \"pallid\", \"robot\", \"audible\", \"cuivocal\",\n",
    "    \"paucity\", \"epistemology\", \"florted\", \"decide\", \"pastiche\",\n",
    "    \"verdid\", \"abysmal\", \"lucid\", \"betray\", \"funny\"\n",
    "]\n",
    "\n",
    "# Define the demographics and metadata options\n",
    "demographics = {\n",
    "    \"education\": {\"Less than high school\": 1, \"High school\": 2, \"University degree\": 3, \"Graduate degree\": 4},\n",
    "    \"urban\": {\"Rural\": 1, \"Suburban\": 2, \"Urban\": 3},\n",
    "    \"gender\": {\"Male\": 1, \"Female\": 2, \"Other\": 3},\n",
    "    \"engnat\": {\"Yes\": 1, \"No\": 2},\n",
    "    \"age\": None,  # Numeric input\n",
    "    \"hand\": {\"Right\": 1, \"Left\": 2, \"Both\": 3},\n",
    "    \"religion\": {\n",
    "        \"Agnostic\": 1, \"Atheist\": 2, \"Buddhist\": 3, \"Christian (Catholic)\": 4,\n",
    "        \"Christian (Mormon)\": 5, \"Christian (Protestant)\": 6, \"Christian (Other)\": 7,\n",
    "        \"Hindu\": 8, \"Jewish\": 9, \"Muslim\": 10, \"Sikh\": 11, \"Other\": 12\n",
    "    },\n",
    "    \"orientation\": {\"Heterosexual\": 1, \"Bisexual\": 2, \"Homosexual\": 3, \"Asexual\": 4, \"Other\": 5},\n",
    "    \"race\": {\"Asian\": 10, \"Arab\": 20, \"Black\": 30, \"Indigenous Australian\": 40, \"Native American\": 50, \"White\": 60, \"Other\": 70},\n",
    "    \"voted\": {\"Yes\": 1, \"No\": 2},\n",
    "    \"married\": {\"Never married\": 1, \"Currently married\": 2, \"Previously married\": 3},\n",
    "    \"familysize\": None,  # Numeric input\n",
    "    \"major\": None,       # Text input\n",
    "}\n",
    "\n",
    "\n",
    "# Derived fields\n",
    "def derive_information():\n",
    "    try:\n",
    "        ip_data = get(\"https://ipinfo.io\").json()\n",
    "        country = ip_data.get(\"country\", \"Unknown\")\n",
    "    except Exception:\n",
    "        country = \"Unknown\"\n",
    "    screensize = 2 if platform.system() in [\"Linux\", \"Windows\"] else 1\n",
    "    uniquenetworklocation = 1\n",
    "    source = 1\n",
    "    return country, screensize, uniquenetworklocation, source\n",
    "\n",
    "def save_user_inputs(inputs):\n",
    "    \"\"\"\n",
    "    Save user inputs to the CSV file with appropriate column names and numeric answers.\n",
    "\n",
    "    Parameters:\n",
    "        inputs (list): List of responses collected from the user.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Collect metadata\n",
    "        country, screensize, uniquenetworklocation, source = derive_information()\n",
    "\n",
    "        # Process inputs\n",
    "        dass_responses = [dass_options.get(response, None) for response in inputs[:42]]\n",
    "        tipi_responses = [tipi_options.get(response, None) for response in inputs[42:52]]\n",
    "        vcl_responses = [1 if response else 0 for response in inputs[52:68]]\n",
    "        demographics_responses = inputs[68:-1]  # Exclude the terms checkbox\n",
    "\n",
    "        # Ensure all demographic responses are present and assign defaults if missing\n",
    "        demographics_keys = [\n",
    "            \"education\", \"urban\", \"gender\", \"engnat\", \"age\", \"hand\", \"religion\",\n",
    "            \"orientation\", \"race\", \"voted\", \"married\", \"familysize\", \"major\"\n",
    "        ]\n",
    "        demographics_data = {key: demographics_responses[i] if i < len(demographics_responses) else None\n",
    "                             for i, key in enumerate(demographics_keys)}\n",
    "\n",
    "        # Prepare the row data\n",
    "        data = {\n",
    "            **{f\"Q{i}A\": dass_responses[i - 1] for i in range(1, 43)},\n",
    "            **{f\"TIPI{i}\": tipi_responses[i - 1] for i in range(1, 11)},\n",
    "            **{f\"VCL{i}\": vcl_responses[i - 1] for i in range(1, 17)},\n",
    "            \"country\": country,\n",
    "            \"source\": source,\n",
    "            \"screensize\": screensize,\n",
    "            \"uniquenetworklocation\": uniquenetworklocation,\n",
    "            **demographics_data,\n",
    "        }\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([data])\n",
    "\n",
    "        # Save or append to the CSV file\n",
    "        if not os.path.exists(output_file):\n",
    "            # Add column headers if the file doesn't exist\n",
    "            df.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            # Append without headers if the file exists\n",
    "            df.to_csv(output_file, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        return \"Inputs saved successfully!\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving inputs: {e}\")\n",
    "        return f\"An error occurred while saving the inputs: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79db90db-ffd1-4ff8-bc08-3eac115ad09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Function to load models and make predictions\n",
    "def predict_user_input(preprocessed_data):\n",
    "    \"\"\"\n",
    "    Predict Depression, Stress, and Anxiety levels based on preprocessed user input.\n",
    "\n",
    "    Parameters:\n",
    "        preprocessed_data (tuple): A tuple containing the preprocessed datasets for Depression, Stress, and Anxiety.\n",
    "\n",
    "    Returns:\n",
    "        dict: Predictions for Depression, Stress, and Anxiety levels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Unpack the preprocessed datasets\n",
    "        Depression, Stress, Anxiety = preprocessed_data\n",
    "\n",
    "        # Load pre-trained models\n",
    "        depression_model = joblib.load(\"random_forest_Depression.pkl\")\n",
    "        stress_model = joblib.load(\"random_forest_stress.pkl\")\n",
    "        anxiety_model = joblib.load(\"random_forest_anxiety.pkl\")\n",
    "\n",
    "        # Ensure there is at least one row to predict (latest user input)\n",
    "        if Depression.empty or Stress.empty or Anxiety.empty:\n",
    "            raise ValueError(\"Preprocessed datasets are empty. Please check the preprocessing step.\")\n",
    "\n",
    "        # Predict for the latest entry\n",
    "        depression_prediction = depression_model.predict(Depression.iloc[[-1]])[0]\n",
    "        stress_prediction = stress_model.predict(Stress.iloc[[-1]])[0]\n",
    "        anxiety_prediction = anxiety_model.predict(Anxiety.iloc[[-1]])[0]\n",
    "\n",
    "        # Return predictions as a dictionary\n",
    "        return {\n",
    "            \"Depression\": depression_prediction,\n",
    "            \"Stress\": stress_prediction,\n",
    "            \"Anxiety\": anxiety_prediction,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return {\"Error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6c29e9-5791-4aca-9a2f-c0179db50155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import os\n",
    "from requests import get\n",
    "# Process and Predict Function\n",
    "# Process and Predict Function\n",
    "def process_and_predict(*inputs):\n",
    "    \"\"\"\n",
    "    Process user input, update the CSV file, preprocess the data, and predict the latest input values.\n",
    "\n",
    "    Parameters:\n",
    "        inputs: User responses collected from the Gradio interface.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Messages and predictions for Depression, Stress, and Anxiety.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Inputs received from Gradio:\", inputs)  # Debugging: Log Gradio inputs\n",
    "\n",
    "        # Step 1: Save user inputs to the CSV file\n",
    "        save_status = save_user_inputs(inputs)\n",
    "        print(\"Save status:\", save_status)  # Debugging: Log save status\n",
    "        if \"successfully\" not in save_status:\n",
    "            return save_status, None, None, None\n",
    "\n",
    "        # Step 2: Load and preprocess the updated CSV file\n",
    "        output_file = \"survey_results.csv\"\n",
    "        if not os.path.exists(output_file):\n",
    "            return \"Error: survey_results.csv file not found.\", None, None, None\n",
    "\n",
    "        updated_data = pd.read_csv(output_file)\n",
    "        print(\"Loaded data shape:\", updated_data.shape)  # Debugging: Log CSV shape\n",
    "        print(\"Loaded data columns:\", updated_data.columns.tolist())  # Debugging: Log CSV columns\n",
    "\n",
    "        if updated_data.empty:\n",
    "            return \"Error: CSV file is empty. No data to preprocess.\", None, None, None\n",
    "\n",
    "        # Preprocess the data\n",
    "        Depression, Stress, Anxiety = preprocess_data(updated_data)\n",
    "        \n",
    "        \n",
    "        # Step 3: Ensure preprocessed data is not empty\n",
    "        print(\"Depression dataset shape:\", Depression.shape)\n",
    "        print(\"Stress dataset shape:\", Stress.shape)\n",
    "        print(\"Anxiety dataset shape:\", Anxiety.shape)\n",
    "\n",
    "        if Depression.empty or Stress.empty or Anxiety.empty:\n",
    "            print(\"Error: Preprocessed data is empty.\")\n",
    "            return (\n",
    "                \"Error: Preprocessed data is empty. Please check the input data or preprocessing logic.\",\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "\n",
    "        # Step 4: Load pre-trained models\n",
    "        try:\n",
    "            depression_model = joblib.load(\"random_forest_Depression.pkl\")\n",
    "            print(\"Depression model loaded successfully.\")\n",
    "            stress_model = joblib.load(\"random_forest_stress.pkl\")\n",
    "            print(\"Stress model loaded successfully.\")\n",
    "            anxiety_model = joblib.load(\"random_forest_anxiety.pkl\")\n",
    "            print(\"Anxiety model loaded successfully.\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: Model file not found - {e}\")\n",
    "            return f\"Error: Model file not found - {e}\", None, None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error while loading models: {e}\")\n",
    "            return f\"Unexpected error: {e}\", None, None, None\n",
    "\n",
    "        # Step 5: Predict the latest user input\n",
    "        try:\n",
    "            print(\"Preparing input for Depression prediction...\")\n",
    "            print(\"Shape of input data for Depression prediction:\", Depression.iloc[[-1], :-1].shape)\n",
    "            print(\"Input data for Depression prediction:\", Depression.iloc[[-1], :-1])\n",
    "            Depression_encoded = encode_demographics(Depression)\n",
    "            Anxiety_encoded= encode_demographics(Anxiety)\n",
    "            Stress_encoded = encode_demographics(Stress)\n",
    "            with open(\"feature_names.txt\", \"r\") as f:\n",
    "                trained_features = f.read().splitlines()\n",
    "            Depression_encoded = Depression_encoded.reindex(columns=trained_features, fill_value=0)\n",
    "\n",
    "            with open(\"feature_names1.txt\", \"r\") as f:\n",
    "                trained_features = f.read().splitlines()\n",
    "            Anxiety_encoded = Anxiety_encoded.reindex(columns=trained_features, fill_value=0)\n",
    "\n",
    "            with open(\"feature_names2.txt\", \"r\") as f:\n",
    "                trained_features = f.read().splitlines()\n",
    "            Stress_encoded = Stress_encoded.reindex(columns=trained_features, fill_value=0)\n",
    "\n",
    "            depression_prediction = depression_model.predict(Depression_encoded.iloc[[-1]])[0]\n",
    "            print(f\"Depression Prediction: {depression_prediction}\")\n",
    "\n",
    "            stress_prediction = stress_model.predict(Stress_encoded.iloc[[-1]])[0]\n",
    "            print(f\"Stress Prediction: {stress_prediction}\")\n",
    "\n",
    "            anxiety_prediction = anxiety_model.predict(Anxiety_encoded.iloc[[-1]])[0]\n",
    "            print(f\"Anxiety Prediction: {anxiety_prediction}\")\n",
    "\n",
    "            # print(\"Responses saved and processed successfully!\")\n",
    "            # print(f\"Depression Level: {depression_prediction}\")\n",
    "            # print(f\"Stress Level: {stress_prediction}\")\n",
    "            # print(f\"Anxiety Level: {anxiety_prediction}\")\n",
    "\n",
    "            return (\n",
    "                \"Responses saved and processed successfully!\",\n",
    "                f\"Depression Level: {depression_prediction}\",\n",
    "                f\"Stress Level: {stress_prediction}\",\n",
    "                f\"Anxiety Level: {anxiety_prediction}\",\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during predictions: {e}\")\n",
    "            return f\"Error during predictions: {e}\", None, None, None\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {e}\", None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17ba4e7c-93db-445e-9cae-636d1ccd8fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs received from Gradio: (   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  engnat  age   hand  \\\n",
      "0    2    1    4    2    1    2    3    4    1     2  ...     Yes   11   Left   \n",
      "1    2    1    4    2    1    2    3    4    1     2  ...     Yes   11   Left   \n",
      "2    2    1    3    4    1    2    3    4    1     2  ...     Yes   25  Right   \n",
      "3    3    3    4    4    1    3    2    1    4     2  ...     Yes   56   Left   \n",
      "4    1    4    3    2    1    2    3    4    4     3  ...     Yes   22  Right   \n",
      "5    2    3    4    4    2    1    4    3    2     2  ...      No   21   Left   \n",
      "6    4    3    3    2    1    2    3    4    1     3  ...     Yes   22  Right   \n",
      "7    2    3    2    3    2    1    4    4    2     3  ...     Yes   19   Both   \n",
      "8    1    3    2    3    4    4    2    3    4     2  ...     Yes   65  Right   \n",
      "9    1    3    4    2    2    3    1    2    1     2  ...      No   13   Both   \n",
      "\n",
      "                 religion   orientation                   race  voted  \\\n",
      "0                Buddhist      Bisexual                  Black    Yes   \n",
      "1                Buddhist      Bisexual                  Black    Yes   \n",
      "2                 Atheist    Homosexual                  Black    Yes   \n",
      "3       Christian (Other)      Bisexual                  Asian    Yes   \n",
      "4                 Atheist    Homosexual                  Black    Yes   \n",
      "5  Christian (Protestant)      Bisexual  Indigenous Australian    Yes   \n",
      "6                   Hindu         Other                  Asian    Yes   \n",
      "7                   Hindu      Bisexual                   Arab    Yes   \n",
      "8                   Hindu  Heterosexual                  Asian    Yes   \n",
      "9    Christian (Catholic)      Bisexual                   Arab     No   \n",
      "\n",
      "             married  familysize      major  \n",
      "0      Never married           6  computers  \n",
      "1      Never married           6  computers  \n",
      "2  Currently married          10  computers  \n",
      "3  Currently married           6         ds  \n",
      "4      Never married           8  computers  \n",
      "5      Never married          10  computers  \n",
      "6      Never married           2  computers  \n",
      "7      Never married           7    science  \n",
      "8  Currently married           5         cs  \n",
      "9      Never married          12         cS  \n",
      "\n",
      "[10 rows x 85 columns],)\n",
      "Error saving inputs: unhashable type: 'DataFrame'\n",
      "Save status: An error occurred while saving the inputs: unhashable type: 'DataFrame'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"An error occurred while saving the inputs: unhashable type: 'DataFrame'\",\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"survey_results.csv\")\n",
    "process_and_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30557e56-7eea-4167-b44b-6ab80ab656a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Gradio Interface\n",
    "dass_inputs = [gr.Radio(label=q, choices=list(dass_options.keys())) for q in dass_questions]\n",
    "tipi_inputs = [gr.Radio(label=q, choices=list(tipi_options.keys())) for q in tipi_questions]\n",
    "vcl_inputs = [gr.Checkbox(label=q) for q in vcl_words]\n",
    "\n",
    "demographics_inputs = [\n",
    "    gr.Radio(label=key.capitalize(), choices=list(options.keys())) if options else\n",
    "    (gr.Number(label=key.capitalize()) if key in [\"age\", \"familysize\"] else gr.Textbox(label=\"Major\"))\n",
    "    for key, options in demographics.items()\n",
    "]\n",
    "\n",
    "terms_and_conditions = gr.Checkbox(label=\"I agree to the terms and conditions\", value=False)\n",
    "\n",
    "all_inputs = dass_inputs + tipi_inputs + vcl_inputs + demographics_inputs + [terms_and_conditions]\n",
    "\n",
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=process_and_predict,\n",
    "    inputs=all_inputs,\n",
    "    outputs=[\"text\", \"text\", \"text\", \"text\"],\n",
    "    title=\"Survey with Predictions\",\n",
    "    description=\"Submit responses to predict Depression, Stress, and Anxiety levels.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f92f2a-02c7-4591-bf2b-c6769c51fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ed6e1-39d3-43c9-b236-3bac271fc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train=pd.read_csv(\"Datasets_test/X_train_depression.csv\")\n",
    "trained_features = list(X_train.columns)  # Assuming X_train is a DataFrame\n",
    "with open(\"feature_names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trained_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train=pd.read_csv(\"Datasets_test/X_train_anxiety.csv\")\n",
    "trained_features = list(X_train.columns)  # Assuming X_train is a DataFrame\n",
    "with open(\"feature_names1.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trained_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train=pd.read_csv(\"Datasets_test/X_train_stress.csv\")\n",
    "trained_features = list(X_train.columns)  # Assuming X_train is a DataFrame\n",
    "with open(\"feature_names2.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trained_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a0544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
